{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jjGpR672j0b2fxNKophIDoWMdnG9Aw76","timestamp":1716302625699}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fmTBGEgHKnS","executionInfo":{"status":"ok","timestamp":1715751503688,"user_tz":-330,"elapsed":30397,"user":{"displayName":"K S Sathwikha yaadava","userId":"00989329422560304819"}},"outputId":"30784fdb-5799-4292-9477-dd8995b3da72"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:03<00:00, 69.4MB/s]\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:06<00:00, 82.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["AlexNet: AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n","\n","VGG16: VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"]}],"source":["import torch\n","import torchvision.models as models\n","\n","# Load pre-trained AlexNet\n","alexnet = models.alexnet(pretrained=True)\n","alexnet.eval()\n","\n","# Load pre-trained VGGNet\n","vgg16 = models.vgg16(pretrained=True)\n","vgg16.eval()\n","\n","# Print the models\n","print(\"AlexNet:\", alexnet)\n","print(\"\\nVGG16:\", vgg16)\n"]},{"cell_type":"code","source":["from torchvision import transforms\n","from PIL import Image\n","import urllib.request"],"metadata":{"id":"5hRIwhWyH60W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n"],"metadata":{"id":"Wew1qFIwHXjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image(model, image_path, transform):\n","    # Load and preprocess the image\n","    image = Image.open(image_path)\n","    image = transform(image).unsqueeze(0)  # Add batch dimension\n","\n","    # Make prediction\n","    with torch.no_grad():\n","        outputs = model(image)\n","        _, predicted = torch.max(outputs, 1)\n","        return predicted.item()\n"],"metadata":{"id":"wZ-y6kMiIGo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path = \"/content/Tree.jpg\""],"metadata":{"id":"g8Cn-SAYH841"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alexnet_prediction = predict_image(alexnet, image_path, transform)\n","print(\"AlexNet prediction:\", alexnet_prediction)\n","\n","# Predict using VGGNet\n","vgg16_prediction = predict_image(vgg16, image_path, transform)\n","print(\"VGG16 prediction:\", vgg16_prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYm0S-0XICGe","executionInfo":{"status":"ok","timestamp":1715751883486,"user_tz":-330,"elapsed":1267,"user":{"displayName":"K S Sathwikha yaadava","userId":"00989329422560304819"}},"outputId":"5e8e11b7-e079-401a-90a8-65f87353a2db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AlexNet prediction: 912\n","VGG16 prediction: 975\n"]}]},{"cell_type":"code","source":["# Load class labels\n","with open(\"imagenet_classes.txt\") as f:\n","    class_labels = [line.strip() for line in f.readlines()]\n","\n","# Print predicted labels\n","print(\"AlexNet prediction:\", class_labels[alexnet_prediction])\n","print(\"VGG16 prediction:\", class_labels[vgg16_prediction])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SGDNvVMkJY8x","executionInfo":{"status":"ok","timestamp":1715752033386,"user_tz":-330,"elapsed":409,"user":{"displayName":"K S Sathwikha yaadava","userId":"00989329422560304819"}},"outputId":"20633e29-2469-42d1-ba03-bad5400bad14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AlexNet prediction: 908, wing\n","VGG16 prediction: 971, bubble\n"]}]}]}